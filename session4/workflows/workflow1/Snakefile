workdir: "../.." # With this we can specify where should Snakemake look for things relative to this path

rule rename_array:
    input:
        "data/raw/array.npy"
    output:
        "data/processed/array_renamed.npy"
    run:
        import numpy as np
        data = np.load(input[0])
        np.save(output[0], data)

rule combine_two_arrays:
    input: 
        "data/raw/array1.npy",
        "data/raw/array2.npy"
    output:
        "data/processed/combined_array.npy"
    run:
        import numpy as np
        array1 = np.load(input[0])
        array2 = np.load(input[1])
        data = np.concatenate((array1, array2))
        np.save(output[0], data)

rule change_csv_to_parquet:
    input:
        "/workspace/iBOTS-Developing-Data-Analysis-Projects/session4/data/raw/session.csv"
    output: 
        "/workspace/iBOTS-Developing-Data-Analysis-Projects/session4/data/raw/session.parquet"
    run:
        import pandas as pd
        import pyarrow as pa
        import pyarrow.parquet as pq
        df = pd.read_csv(input[0])
        #convert DataFrame to Apache Arrow Table
        table = pa.Table.from_pandas(df)
        #Parquet with Brotli compression
        pq.write_table(table,output[0])

rule standardized_array:
    input:
        "/workspace/iBOTS-Developing-Data-Analysis-Projects/session4/data/raw/array.npy"
    output:
        "/workspace/iBOTS-Developing-Data-Analysis-Projects/session4/data/raw/array_standardized.npy"
    run:
        import numpy as np
        data = np.load(input[0])
        standardized = (data - np.mean(data))/np.std(data)
        np.save(output[0],standardized)

rule normalized_array:
    input:
        "/workspace/iBOTS-Developing-Data-Analysis-Projects/session4/data/raw/array.npy"
    output:
        "/workspace/iBOTS-Developing-Data-Analysis-Projects/session4/data/raw/array_normalized.npy"
    shell:
        "python /workspace/iBOTS-Developing-Data-Analysis-Projects/session4/scripts/normalize_array.py {input[0]} {output[0]}"

rule extract_valid_trials:
    input:
        "data/raw/session.csv"
    output:
        "data/processed/session_valid.csv"
    shell:
        "python scripts/extract_valid_trials.py {input[0]} {output[0]}"

rule combine_two_arrays2:
    input: 
        "data/raw/array1.npy",
        "data/raw/array2.npy"
    output:
        "data/processed/combined_data.csv"
    run:
        import numpy as np
        array1 = np.load(input[0])
        array2 = np.load(input[1])
        data = np.concatenate((array1, array2))
        reshape_array = data.reshape(-1,2)
        np.savetxt(output[0],reshape_array,delimiter=",")

rule combine_two_arrays_different:
    input: 
        "data/raw/array1.npy",
        "data/raw/array2.npy"
    output:
        "data/processed/combined_data.csv"
    run:
        import numpy as np
        import pandas as pd
        array1 = np.load(input[0])
        array2 = np.load(input[1])
        df=pd.DataFrame({
            "array1": array1,
            "array2":array2
        })
        df.to_csv(output[0],index=False)




